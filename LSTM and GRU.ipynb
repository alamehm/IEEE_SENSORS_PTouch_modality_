{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"LSTM and GRU.ipynb","provenance":[{"file_id":"1wRK-LmzcUEtBm7dv-bm6yKmy9quLYS8G","timestamp":1602416903291},{"file_id":"1lk5wJb19lcw9SleS7wlvreSHn_oDZymT","timestamp":1589064018165}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"scrolled":true,"id":"xBZaZW9gtMA2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!ls \"/content/drive/My Drive/Data\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Q-UWFKvnWdJ"},"source":["from numpy import mean\n","from numpy import std\n","from numpy import dstack\n","from numpy import reshape\n","from pandas import read_csv\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.layers import GRU\n","from keras.utils import to_categorical\n","from matplotlib import pyplot\n","import numpy as np\n","import gc,os,cv2\n","import asyncio\n","from time import gmtime, strftime\n","import sklearn\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"CH-xANSutMCj"},"source":["def load_dataset5 (fold = 0,prefix=''):\n","\t#print (prefix)\n","\n","\n","\tX1 = read_csv(prefix+'brushing.txt', header=None, delim_whitespace=False) \n","\tX2 = read_csv(prefix+'rolling.txt', header=None, delim_whitespace=False) \n","\tX3 = read_csv(prefix+'sliding.txt', header=None, delim_whitespace=False) \n","\tprint (prefix)\n","\n","\tmu = np.average([np.average(X1),np.average(X2),np.average(X3)]) \n","\tstd = np.std([np.std(X1),np.std(X2),np.std(X3)]) \n"," \n","\tn_features = \t16\n","\ttimelength = 8\n","\n","\tX1=X1.values\n","\tX2=X2.values\n","\tX3=X3.values\n","\n","\tX = np.zeros((X1.shape[0]*3,X1.shape[1]))\n","\tX [ 0:X1.shape[0],:] = X1\n","\tX [X1.shape[0]:X1.shape[0]*2,:]=X2\n","\tX [X1.shape[0]*2:X1.shape[0]*3,:]=X3\n","\tX = (X-mu)/std ; print (\" with regularization\"); \n","\t#print (\"without regularization\")\n","\tX = np.reshape((X),(X.shape[0]//timelength,-1,n_features))\n","\n","\n","\tY = read_csv(prefix + 'Label.txt', header=None, delim_whitespace=True)\n","\tY = Y.values\n","\ty = Y\n","\t#y = to_categorical(Y)\n","\t#X,y = shuffle(X,y)\n","\tskf = StratifiedKFold(n_splits=5,shuffle = False,random_state=None)\n","\t#print (skf.get_n_splits(X, y))\n","\tlst = list(skf.split(X,y))\n","\ttrain_index, test_index  = list(skf.split(X,y))[fold]\n","\treturn X[train_index],to_categorical( y[train_index]), X[test_index], to_categorical(y[test_index])\n","\n","# fit and evaluate a model\n","def evaluate_model(trainX, trainy, testX, testy,epochs,batch_size):\n","\t#verbose, epochs, batch_size = 1, 56, 100\n","\t#number of parameters of a single LSTM layer: (4 * ((size_of_input + 1) * size_of_output + size_of_output^2))\n","\tverbose = 0\n","\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n","\t#print (\"features \" , n_features)\n","\t#print (\"Outputs \" , n_outputs)\n","\tmodel = Sequential()\n","# \tmodel.add(LSTM(100, input_shape=(n_timesteps,n_features),return_sequences=True)) ;print (\"first lstm layer 100 neurons\") # original 100\n","\tmodel.add(LSTM(10, input_shape=(n_timesteps,n_features))); print (\"LSTM layer 10 neurons\") # original 100 ; \n","\t#model.add(Dropout(0.5))\n","\t#model.add(Dense(10, activation='relu')) # original 200\n","\tmodel.add(Dense(n_outputs, activation='softmax'))\n","\t#model.summary()\n","\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\t# fit network\n","\thistory = model.fit(trainX, trainy,  epochs=epochs, batch_size=batch_size, verbose=verbose)\n","\t#history = model.fit(trainX, trainy, validation_split=0.25, epochs=epochs, batch_size=batch_size, verbose=verbose) # it seems worse with validation\n","\t# evaluate model\n","\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n","\tprint ( \"verbose \",verbose, \" epochs \",epochs, \" batch_size \",batch_size)\n","\treturn accuracy\n","    \n","\n","def evaluate_model_GRU(trainX, trainy, testX, testy,epochs,batch_size):\n","\n","\tverbose = 0\n","\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n","\n","\tmodel = Sequential()\n","\n","\tmodel.add(GRU(10, input_shape=(n_timesteps,n_features))); \n","\tmodel.add(Dense(n_outputs, activation='softmax'))\n","\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\thistory = model.fit(trainX, trainy,  epochs=epochs, batch_size=batch_size, verbose=verbose)\n","\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n","\treturn accuracy\n","\n","# summarize scores\n","def summarize_results(scores):\n","\tprint(scores)\n","\tm, s = mean(scores), std(scores)\n","\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n","\n","# run an experiment\n","def run_experiment(myDataset,epochs,batch_size,repeats=3):\n","\t# load data\n","\ttrainX, trainy, testX, testy = myDataset\n","\tprint('train:', trainX.shape)\n","\tprint('train_Label:', trainX.shape)\n","\tprint('test:', testX.shape)\n","\tprint('test_Label:', testy.shape)\n","\t# repeat experiment\n","\tscores = list()\n","\tfor r in range(repeats):\n","\t\tscore = evaluate_model_GRU(trainX, trainy, testX, testy,epochs,batch_size)\n","\t\t#score = evaluate_model(trainX, trainy, testX, testy,epochs,batch_size)\n","\t\tscore = score * 100.0\n","\t\t#print('>#%d: %.3f' % (r+1, score), strftime(\"%d/%m/%Y %H:%M:%S +0000\", gmtime()))\n","\t\tscores.append(score)\n","\t# summarize results\n","\tsummarize_results(scores)\n","\tprint(strftime(\"%d/%m/%Y %H:%M:%S +0000\", gmtime()))\n","\n","print (\"starting ......\")\n","gc.enable()\n","#for i in [124]:\n","for  ff in range(0,5):\n","\tmyDataset = load_dataset5(fold = ff, prefix = '/content/drive/My Drive/DeepLearning/Average/output=8/')\n","\tprint (\"starting Fold \", ff )\n","\tfor i in [48,96]:\n","\t\tfor j in [48,96]:\n","\t\t#for j in [96]:\n","\t\t\tprint (\"Fold \", ff, \"epochs:\",i,\", batch: \",j)\n","\t\t\trun_experiment(myDataset,epochs=i, batch_size=j,repeats = 10)\n","\t\t\tgc.collect()\n","print (\"finished!\")\n"],"execution_count":null,"outputs":[]}]}