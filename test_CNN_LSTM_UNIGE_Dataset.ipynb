{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# code from : \n",
    "# https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/\n",
    "# lstm model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from numpy import reshape\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import gc\n",
    "import asyncio\n",
    "from time import gmtime, strftime\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config =  tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    " # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "IPython.tab_as_tab_everywhere = function(use_tabs) {\n",
       "    if (use_tabs === undefined) {\n",
       "        use_tabs = true; \n",
       "    }\n",
       "\n",
       "    // apply setting to all current CodeMirror instances\n",
       "    IPython.notebook.get_cells().map(\n",
       "        function(c) {  return c.code_mirror.options.indentWithTabs=use_tabs;  }\n",
       "    );\n",
       "    // make sure new CodeMirror instances created in the future also use this setting\n",
       "    CodeMirror.defaults.indentWithTabs=use_tabs;\n",
       "\n",
       "    };\n",
       "\n",
       "IPython.tab_as_tab_everywhere()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "IPython.tab_as_tab_everywhere = function(use_tabs) {\n",
    "    if (use_tabs === undefined) {\n",
    "        use_tabs = true; \n",
    "    }\n",
    "\n",
    "    // apply setting to all current CodeMirror instances\n",
    "    IPython.notebook.get_cells().map(\n",
    "        function(c) {  return c.code_mirror.options.indentWithTabs=use_tabs;  }\n",
    "    );\n",
    "    // make sure new CodeMirror instances created in the future also use this setting\n",
    "    CodeMirror.defaults.indentWithTabs=use_tabs;\n",
    "\n",
    "    };\n",
    "\n",
    "IPython.tab_as_tab_everywhere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset2(prefix='C:/Users/alame/OneDrive - unige.it/Documents/TactileDataset/cleand (6144)/(64x64) time frames(images)/RGB/Features/'):\n",
    "\t#X1 = read_csv(prefix+'rolling/'+'rolling_all_t1_t24.txt', header=None, delim_whitespace=True) \n",
    "\t#X2 = read_csv(prefix+'sliding/'+'sliding_all_t1_t24.txt', header=None, delim_whitespace=True) \n",
    "\tX1 = read_csv(prefix+'rolling/'+'rolling_all_t1_t24.txt', header=None, delim_whitespace=True) \n",
    "\tX2 = read_csv(prefix+'sliding/'+'sliding_all_t1_t24.txt', header=None, delim_whitespace=True) \n",
    "\tX3 = read_csv(prefix+'brushing/'+'brushing_all_t1_t24.txt', header=None, delim_whitespace=True) \n",
    "\tn_features = 8192\n",
    "\t#A=X1.values\n",
    "\t#B=X2.values\n",
    "\tXlen= X1.shape[0]\n",
    "\tX1=X1.values\n",
    "\tX2=X2.values\n",
    "\tX3=X3.values\n",
    "\t\n",
    "\tX1_train = X1[0:4*Xlen//5,:]\n",
    "\tX2_train = X2[0:4*Xlen//5,:]\n",
    "\tX3_train = X3[0:4*Xlen//5,:]\n",
    "\t\n",
    "\tX_train = np.zeros((X1_train.shape[0]*2,X1_train.shape[1]))\n",
    "\tX_train [ 0:X1_train.shape[0],:] = X1_train\n",
    "\tX_train [X1_train.shape[0]:X1_train.shape[0]*2,:]=X2_train\n",
    "\t\n",
    "\tX1_test = X1[4*Xlen//5:Xlen,:]\n",
    "\tX2_test = X2[4*Xlen//5:Xlen,:]\n",
    "\tX_test = np.zeros((X1_test.shape[0]*2,X1_test.shape[1]))\n",
    "\tX_test[ 0:X1_test.shape[0],:] = X1_test\n",
    "\tX_test [X1_test.shape[0]:X1_test.shape[0]*2,:]=X2_test\n",
    "\t#X= np.concatenate (A,B,1)\n",
    "\t#print (np.shape(X1))\n",
    "\t#print (np.shape(X2))\n",
    "\tY = read_csv(prefix + 'y.txt', header=None, delim_whitespace=True)\n",
    "\tY=Y.values\n",
    "\tY=to_categorical(Y)\n",
    "\tYlen= Y.shape[0]\n",
    "\tY1 = Y[0:Ylen//2,:]\n",
    "\tY2 = Y[Ylen//2:Ylen,:]\n",
    "\tY1_train = Y1[0:4*Ylen//5//2,:]\n",
    "\tY2_train = Y2[0:4*Ylen//5//2,:]\n",
    "\tY_train = np.zeros((Y1_train.shape[0]*2,Y1_train.shape[1]))\n",
    "\tY_train [ 0:Y1_train.shape[0],:] = Y1_train\n",
    "\tY_train [Y1_train.shape[0]:Y1_train.shape[0]*2,:]=Y2_train\n",
    "\t#Y_train = Y1_train.append(Y2_train)\n",
    "\tY1_test = Y1[4*Ylen//5//2:Ylen//2,:]\n",
    "\tY2_test = Y2[4*Ylen//5//2:Ylen//2,:]\n",
    "\tY_test = np.zeros((Y1_test.shape[0]*2,Y1_test.shape[1]))\n",
    "\tY_test [ 0:Y1_test.shape[0],:] = Y1_test\n",
    "\tY_test [Y1_test.shape[0]:Y1_test.shape[0]*2,:]=Y2_test\n",
    "\ttimelength = 24\n",
    "\tX_train= np.reshape((X_train),(X_train.shape[0]//timelength,-1,n_features))\n",
    "\tX_test= np.reshape((X_test),(X_test.shape[0]//timelength,-1,n_features))\n",
    "\t#Y_train= np.reshape((Y_train),(Y_train.shape[0]//timelength,-1,8192))\n",
    "\t#Y_test= np.reshape((Y_test),(Y_test.shape[0]//timelength,-1,8192))\n",
    "\treturn X_train, Y_train, X_test ,Y_test \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset3(prefix='C:/Users/alame/OneDrive - unige.it/Documents/TactileDataset/cleand (6144)/(64x64) time frames(images)/RGB/Features/Features(ResNet150-v2)/'):\n",
    "\n",
    "# \tX1 = read_csv(prefix+'rolling/'+'rolling_all_t1_t24.txt', header=None, delim_whitespace=True) \n",
    "# \tX2 = read_csv(prefix+'sliding/'+'sliding_all_t1_t24.txt', header=None, delim_whitespace=True) \n",
    "# \tX3 = read_csv(prefix+'brushing/'+'brushing_all_t1_t24.txt', header=None, delim_whitespace=True) \n",
    "\tX1 = read_csv(prefix+'rolling/'+'rolling_all_resnet150.txt', header=None, delim_whitespace=True) \n",
    "\tX2 = read_csv(prefix+'sliding/'+'sliding_all_resnet150.txt', header=None, delim_whitespace=True) \n",
    "\tX3 = read_csv(prefix+'brushing/'+'brushing_all_resnet150.txt', header=None, delim_whitespace=True) \n",
    "\n",
    "\tn_features = 8192\n",
    "\ttimelength = 24\n",
    "\n",
    "\t#A=X1.values\n",
    "\t#B=X2.values\n",
    "\tXlen= X1.shape[0]\n",
    "\tX1=X1.values\n",
    "\tX2=X2.values\n",
    "\tX3=X3.values\n",
    "\t\n",
    "\tX1_train = X1[0:4*Xlen//5,:]\n",
    "\tX2_train = X2[0:4*Xlen//5,:]\n",
    "\tX3_train = X3[0:4*Xlen//5,:]\n",
    "\t\n",
    "\tX_train = np.zeros((X1_train.shape[0]*3,X1_train.shape[1]))\n",
    "\tX_train [ 0:X1_train.shape[0],:] = X1_train\n",
    "\tX_train [X1_train.shape[0]:X1_train.shape[0]*2,:]=X2_train\n",
    "\tX_train [X1_train.shape[0]*2:X1_train.shape[0]*3,:]=X3_train\n",
    "\t\n",
    "\tX1_test = X1[4*Xlen//5:Xlen,:]\n",
    "\tX2_test = X2[4*Xlen//5:Xlen,:]\n",
    "\tX3_test = X3[4*Xlen//5:Xlen,:]\n",
    "\t\n",
    "\tX_test = np.zeros((X1_test.shape[0]*3,X1_test.shape[1]))\n",
    "\tX_test[ 0:X1_test.shape[0],:] = X1_test\n",
    "\tX_test [X1_test.shape[0]:X1_test.shape[0]*2,:]=X2_test\n",
    "\tX_test [X1_test.shape[0]*2:X1_test.shape[0]*3,:]=X3_test\n",
    "\t\n",
    "\t#X= np.concatenate (A,B,1)\n",
    "\t#print (np.shape(X1))\n",
    "\t#print (np.shape(X2))\n",
    "\tY = read_csv(prefix + 'y.txt', header=None, delim_whitespace=True)\n",
    "\tY = Y.values\n",
    "\tY = to_categorical(Y)\n",
    "\tYlen = Y.shape[0]\n",
    "\tY1 = Y[0:Ylen//3,:]\n",
    "\tY2 = Y[Ylen//3:2*Ylen//3,:]\n",
    "\tY3 = Y[2*Ylen//3:Ylen,:]\n",
    "\n",
    "\n",
    "\tY1_train = Y1[0:4*Ylen//5//3,:]\n",
    "\tY2_train = Y2[0:4*Ylen//5//3,:]\n",
    "\tY3_train = Y3[0:4*Ylen//5//3,:]\n",
    "\n",
    "\tY_train = np.zeros((Y1_train.shape[0]*3,Y1_train.shape[1]))\n",
    "\n",
    "\tY_train [ 0:Y1_train.shape[0],:] = Y1_train\n",
    "\tY_train [Y1_train.shape[0]:Y1_train.shape[0]*2,:] = Y2_train\n",
    "\tY_train [Y1_train.shape[0]*2:Y1_train.shape[0]*3,:] = Y3_train\n",
    "\n",
    "\t#Y_train = Y1_train.append(Y2_train)\n",
    "\tY1_test = Y1[4*Ylen//5//3:Ylen//3,:]\n",
    "\tY2_test = Y2[4*Ylen//5//3:Ylen//3,:]\n",
    "\tY3_test = Y3[4*Ylen//5//3:Ylen//3,:]\n",
    "\n",
    "\tY_test = np.zeros((Y1_test.shape[0]*3,Y1_test.shape[1]))\n",
    "\tY_test [ 0:Y1_test.shape[0],:] = Y1_test\n",
    "\tY_test [Y1_test.shape[0]:Y1_test.shape[0]*2,:]=Y2_test\n",
    "\tY_test [Y1_test.shape[0]*2:Y1_test.shape[0]*3,:]=Y3_test\n",
    "\n",
    "\tX_train= np.reshape((X_train),(X_train.shape[0]//timelength,-1,n_features))\n",
    "\t#X_train= np.reshape((X_train),(X_train.shape[0],16,256))\n",
    "\tX_test= np.reshape((X_test),(X_test.shape[0]//timelength,-1,n_features))\n",
    "\t#X_test= np.reshape((X_test),(X_test.shape[0],16,256))\n",
    "\t\n",
    "\t#Y_train= np.reshape((Y_train),(Y_train.shape[0]//timelength,-1,8192))\n",
    "\t#Y_test= np.reshape((Y_test),(Y_test.shape[0]//timelength,-1,8192))\n",
    "\treturn X_train, Y_train, X_test ,Y_test \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset4 (prefix='C:/Users/alame/OneDrive - unige.it/Documents/TactileDataset/cleand (6144)/Average in time/output=20/'):\n",
    "\n",
    "# (prefix='C:/Users/alame/OneDrive - unige.it/Documents/TactileDataset/cleand (6144)/(64x64) time frames(images)/RGB/Features/Features(ResNet150-v2)/'):\n",
    "\n",
    "# \tX1 = read_csv(prefix+'rolling/'+'rolling_all_resnet150.txt', header=None, delim_whitespace=True) \n",
    "# \tX2 = read_csv(prefix+'sliding/'+'sliding_all_resnet150.txt', header=None, delim_whitespace=True) \n",
    "# \tX3 = read_csv(prefix+'brushing/'+'brushing_all_resnet150.txt', header=None, delim_whitespace=True) \n",
    "\t#(prefix='C:/Users/alame/OneDrive - unige.it/Documents/TactileDataset/cleand (6144)/Average in time/output=256/Dataset/'):\n",
    "\t#\n",
    "# \tX1 = read_csv(prefix+'rolling/'+'rolling_all_t1_t24.txt', header=None, delim_whitespace=True) \n",
    "# \tX2 = read_csv(prefix+'sliding/'+'sliding_all_t1_t24.txt', header=None, delim_whitespace=True) \n",
    "# \tX3 = read_csv(prefix+'brushing/'+'brushing_all_t1_t24.txt', header=None, delim_whitespace=True) \n",
    "\tX1 = read_csv(prefix+'rolling/'+'rolling_all_20.txt', header=None, delim_whitespace=False) \n",
    "\tX2 = read_csv(prefix+'sliding/'+'sliding_all_20.txt', header=None, delim_whitespace=False) \n",
    "\tX3 = read_csv(prefix+'brushing/'+'brushing_all_20.txt', header=None, delim_whitespace=False) \n",
    "\tprint (prefix)\n",
    "\n",
    "\tmu = np.average([np.average(X1),np.average(X2),np.average(X2)])  ##### here there was a mistake the last X2 should be X3\n",
    "\tstd = np.std([np.std(X1),np.std(X2),np.std(X2)]) \n",
    "\tn_features = 16#8192#\n",
    "\ttimelength = 20#24#200 #24\n",
    "\n",
    "\t#A=X1.values\n",
    "\t#B=X2.values\n",
    "\tXlen= X1.shape[0]\n",
    "\tX1=X1.values\n",
    "\tX2=X2.values\n",
    "\tX3=X3.values\n",
    "\t\n",
    "\tX1_train = X1[0:4*Xlen//5,:]\n",
    "\tX2_train = X2[0:4*Xlen//5,:]\n",
    "\tX3_train = X3[0:4*Xlen//5,:]\n",
    "\t\n",
    "\tX_train = np.zeros((X1_train.shape[0]*3,X1_train.shape[1]))\n",
    "\tX_train [ 0:X1_train.shape[0],:] = X1_train\n",
    "\tX_train [X1_train.shape[0]:X1_train.shape[0]*2,:]=X2_train\n",
    "\tX_train [X1_train.shape[0]*2:X1_train.shape[0]*3,:]=X3_train\n",
    "\t\n",
    "\tX1_test = X1[4*Xlen//5:Xlen,:]\n",
    "\tX2_test = X2[4*Xlen//5:Xlen,:]\n",
    "\tX3_test = X3[4*Xlen//5:Xlen,:]\n",
    "\t\n",
    "\tX_test = np.zeros((X1_test.shape[0]*3,X1_test.shape[1]))\n",
    "\tX_test[ 0:X1_test.shape[0],:] = X1_test\n",
    "\tX_test [X1_test.shape[0]:X1_test.shape[0]*2,:]=X2_test\n",
    "\tX_test [X1_test.shape[0]*2:X1_test.shape[0]*3,:]=X3_test\n",
    "\t\n",
    "\t#X= np.concatenate (A,B,1)\n",
    "\t#print (np.shape(X1))\n",
    "\t#print (np.shape(X2))\n",
    "\tY = read_csv(prefix + 'y.txt', header=None, delim_whitespace=True)\n",
    "\tY = Y.values\n",
    "\tY = to_categorical(Y)\n",
    "\tYlen = Y.shape[0]\n",
    "\tY1 = Y[0:Ylen//3,:]\n",
    "\tY2 = Y[Ylen//3:2*Ylen//3,:]\n",
    "\tY3 = Y[2*Ylen//3:Ylen,:]\n",
    "\n",
    "\n",
    "\tY1_train = Y1[0:4*Ylen//5//3,:]\n",
    "\tY2_train = Y2[0:4*Ylen//5//3,:]\n",
    "\tY3_train = Y3[0:4*Ylen//5//3,:]\n",
    "\n",
    "\tY_train = np.zeros((Y1_train.shape[0]*3,Y1_train.shape[1]))\n",
    "\n",
    "\tY_train [ 0:Y1_train.shape[0],:] = Y1_train\n",
    "\tY_train [Y1_train.shape[0]:Y1_train.shape[0]*2,:] = Y2_train\n",
    "\tY_train [Y1_train.shape[0]*2:Y1_train.shape[0]*3,:] = Y3_train\n",
    "\n",
    "\t#Y_train = Y1_train.append(Y2_train)\n",
    "\tY1_test = Y1[4*Ylen//5//3:Ylen//3,:]\n",
    "\tY2_test = Y2[4*Ylen//5//3:Ylen//3,:]\n",
    "\tY3_test = Y3[4*Ylen//5//3:Ylen//3,:]\n",
    "\n",
    "\tY_test = np.zeros((Y1_test.shape[0]*3,Y1_test.shape[1]))\n",
    "\tY_test [ 0:Y1_test.shape[0],:] = Y1_test\n",
    "\tY_test [Y1_test.shape[0]:Y1_test.shape[0]*2,:]=Y2_test\n",
    "\tY_test [Y1_test.shape[0]*2:Y1_test.shape[0]*3,:]=Y3_test\n",
    "\n",
    "\tX_train= np.reshape((X_train),(X_train.shape[0]//timelength,-1,n_features))\n",
    "\tX_train = (X_train - mu )/ std\n",
    "\t\n",
    "\n",
    "\tX_test= np.reshape((X_test),(X_test.shape[0]//timelength,-1,n_features))\n",
    "\tX_test = (X_test - mu )/ std\n",
    "\t#Y_train= np.reshape((Y_train),(Y_train.shape[0]//timelength,-1,8192))\n",
    "\t#Y_test= np.reshape((Y_test),(Y_test.shape[0]//timelength,-1,8192))\n",
    "\treturn X_train, Y_train, X_test ,Y_test \n",
    "\n",
    "###load_dataset4\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Loading dataset .....\n",
      "C:/Users/alame/OneDrive - unige.it/Documents/TactileDataset/cleand (6144)/Average in time/output=20/\n",
      "dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "print (\"start Loading dataset .....\")\n",
    "myDataset= load_dataset4()\n",
    "# run the experiment\n",
    "print (\"dataset Loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset5 (fold = 0,prefix=''):\n",
    "\t#print (prefix)\n",
    "\n",
    "\n",
    "\tX1 = read_csv(prefix+'rolling/'+'rolling_all.txt', header=None, delim_whitespace=False) \n",
    "\tX2 = read_csv(prefix+'sliding/'+'sliding_all.txt', header=None, delim_whitespace=False) \n",
    "\tX3 = read_csv(prefix+'brushing/'+'brushing_all.txt', header=None, delim_whitespace=False) \n",
    "\tprint (prefix)\n",
    "\n",
    "\tmu = np.average([np.average(X1),np.average(X2),np.average(X3)]) \n",
    "\tstd = np.std([np.std(X1),np.std(X2),np.std(X3)]) \n",
    "\tn_features = 768# tactnet2850 896#8192#2048#\n",
    "\ttimelength = 24#20#200 \n",
    "\n",
    "\t#A=X1.values\n",
    "\t#B=X2.values\n",
    "\t#Xlen= X1.shape[0]\n",
    "\tX1=X1.values\n",
    "\tX2=X2.values\n",
    "\tX3=X3.values\n",
    "\n",
    "\tX = np.zeros((X1.shape[0]*3,X1.shape[1]))\n",
    "\tX [ 0:X1.shape[0],:] = X1\n",
    "\tX [X1.shape[0]:X1.shape[0]*2,:]=X2\n",
    "\tX [X1.shape[0]*2:X1.shape[0]*3,:]=X3\n",
    "\t#X = (X-mu)/std ; print (\" with regularization\"); \n",
    "\tprint (\"without regularization\")\n",
    "\tX = np.reshape((X),(X.shape[0]//timelength,-1,n_features))\n",
    "\n",
    "\n",
    "\tY = read_csv(prefix + 'y.txt', header=None, delim_whitespace=True)\n",
    "\tY = Y.values\n",
    "\ty= Y\n",
    "\t#y = to_categorical(Y)\n",
    "\t#X,y = shuffle(X,y)\n",
    "\tskf = StratifiedKFold(n_splits=5,shuffle = False,random_state=None)\n",
    "\t#print (skf.get_n_splits(X, y))\n",
    "\tlst = list(skf.split(X,y))\n",
    "\ttrain_index, test_index  = list(skf.split(X,y))[fold]\n",
    "\treturn X[train_index],to_categorical( y[train_index]), X[test_index], to_categorical(y[test_index])\n",
    "\t\n",
    "\t\n",
    "# \tfor train_index, test_index in skf.split(X, y):\n",
    "# \t\t#print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "# \t\tX_train, X_test = X[train_index], X[test_index]\n",
    "# \t\ty_train, y_test = y[train_index], y[test_index]\n",
    "# \t\t#print(\"Train and test\" ,X_train , X_test)\n",
    "# \t\t#print (\"\\r\\n\")\n",
    "# \t\tX_train, X_val,y_train,y_val =train_test_split(X_train, y_train,train_size = 0.75 ,shuffle=False)\n",
    "# \t\tprint (\"tr , val\",y_train,y_val)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ALAME This test failed with our data  classified as 320 per row , accuracy 49 - 50 %\n",
    "# load a single file as a numpy array\n",
    "# I will retry using the new method \n",
    "# same was on the new method, making a Standardization works fine\n",
    "\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy,epochs,batch_size):\n",
    "\t#verbose, epochs, batch_size = 1, 56, 100\n",
    "\t#number of parameters of a single LSTM layer: (4 * ((size_of_input + 1) * size_of_output + size_of_output^2))\n",
    "\tverbose = 0\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\t#print (\"features \" , n_features)\n",
    "\t#print (\"Outputs \" , n_outputs)\n",
    "\tmodel = Sequential()\n",
    "# \tmodel.add(LSTM(100, input_shape=(n_timesteps,n_features),return_sequences=True)) ;print (\"first lstm layer 100 neurons\") # original 100\n",
    "\tmodel.add(LSTM(10, input_shape=(n_timesteps,n_features))); print (\"LSTM layer 10 neurons\") # original 100 ; \n",
    "\t#model.add(Dropout(0.5))\n",
    "\t#model.add(Dense(10, activation='relu')) # original 200\n",
    "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\t#model.summary()\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\thistory = model.fit(trainX, trainy,  epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t#history = model.fit(trainX, trainy, validation_split=0.25, epochs=epochs, batch_size=batch_size, verbose=verbose) # it seems worse with validation\n",
    "#\tprint (history.history.keys())\n",
    "# \tplt.plot(history.history['accuracy'])\n",
    "# \t#plt.plot(history.history['val_accuracy'])\n",
    "# \tplt.title('Model accuracy')\n",
    "# \tplt.ylabel('Accuracy')\n",
    "# \tplt.xlabel('Epoch')\n",
    "# \tplt.legend(['Train', 'Val'], loc='upper left')\n",
    "# \tplt.show()\n",
    "\n",
    "# \t# Plot training & validation loss values\n",
    "# \tplt.plot(history.history['loss'])\n",
    "# \t#plt.plot(history.history['val_loss'])\n",
    "# \tplt.title('Model loss')\n",
    "# \tplt.ylabel('Loss')\n",
    "# \tplt.xlabel('Epoch')\n",
    "# \tplt.legend(['Train', 'Val'], loc='upper left')\n",
    "# \tplt.show()\n",
    "\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\tprint ( \"verbose \",verbose, \" epochs \",epochs, \" batch_size \",batch_size)\n",
    "\treturn accuracy\n",
    "    \n",
    "\n",
    "\n",
    "def evaluate_model_GRU(trainX, trainy, testX, testy,epochs,batch_size):\n",
    "\n",
    "\tverbose = 0\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\n",
    "\tmodel.add(GRU(12, input_shape=(n_timesteps,n_features))); print (\"GRU layer 12 neurons\") # original 100 ; \n",
    "\n",
    "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\t#model.summary()\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\thistory = model.fit(trainX, trainy,  epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# \t#history = model.fit(trainX, trainy, validation_split=0.25, epochs=epochs, batch_size=batch_size, verbose=verbose) # it seems worse with validation\n",
    "# \tprint (history.history.keys())\n",
    "# \tplt.plot(history.history['accuracy'])\n",
    "# \t#plt.plot(history.history['val_accuracy'])\n",
    "# \tplt.title('Model accuracy')\n",
    "# \tplt.ylabel('Accuracy')\n",
    "# \tplt.xlabel('Epoch')\n",
    "# \tplt.legend(['Train', 'Val'], loc='upper left')\n",
    "# \tplt.show()\n",
    "\n",
    "# \t# Plot training & validation loss values\n",
    "# \tplt.plot(history.history['loss'])\n",
    "# \t#plt.plot(history.history['val_loss'])\n",
    "# \tplt.title('Model loss')\n",
    "# \tplt.ylabel('Loss')\n",
    "# \tplt.xlabel('Epoch')\n",
    "# \tplt.legend(['Train', 'Val'], loc='upper left')\n",
    "# \tplt.show()\n",
    "\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\tprint ( \"verbose \",verbose, \" epochs \",epochs, \" batch_size \",batch_size)\n",
    "\treturn accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "\tprint(scores)\n",
    "\tm, s = mean(scores), std(scores)\n",
    "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(myDataset,epochs,batch_size,repeats=3):\n",
    "\t# load data\n",
    "\ttrainX, trainy, testX, testy = myDataset\n",
    "\t# repeat experiment\n",
    "\tscores = list()\n",
    "\tfor r in range(repeats):\n",
    "\t\tscore = evaluate_model(trainX, trainy, testX, testy,epochs,batch_size)\n",
    "\t\t#score = evaluate_model(trainX, trainy, testX, testy,epochs,batch_size)\n",
    "\t\tscore = score * 100.0\n",
    "\t\t#print('>#%d: %.3f' % (r+1, score), strftime(\"%d/%m/%Y %H:%M:%S +0000\", gmtime()))\n",
    "\t\tscores.append(score)\n",
    "\t# summarize results\n",
    "\tsummarize_results(scores)\n",
    "\tprint(strftime(\"%d/%m/%Y %H:%M:%S +0000\", gmtime()))\n",
    "\n",
    "print (\"starting ......\")\n",
    "gc.enable()\n",
    "#for i in [124]:\n",
    "for  ff in range(0,5):\n",
    "\t#myDataset = load_dataset5(fold = ff, prefix = 'C:/Users/alame/OneDrive - unige.it/Documents/TactileDataset/cleand (6144)/Average in time/output=20/')\n",
    "\tmyDataset = load_dataset5(fold = ff, prefix = 'C:/Users/alame/OneDrive - unige.it/Documents/TactileDataset/cleand (6144)/TactNetFeatures/26x47/')\n",
    "\tprint (\"starting Fold \", ff )\n",
    "\tfor i in [48,96]:\n",
    "\t\tfor j in [48,96]:\n",
    "\t\t#for j in [96]:\n",
    "\t\t\tprint (\"Fold \", ff, \"epochs:\",i,\", batch: \",j)\n",
    "\t\t\trun_experiment(myDataset,epochs=i, batch_size=j,repeats = 10)\n",
    "\t\t\tgc.collect()\n",
    "print (\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-00dcae34353c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msize_of_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msize_of_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_of_input\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msize_of_output\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msize_of_output\u001b[0m\u001b[1;33m^\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary\n",
    "size_of_input = 16\n",
    "size_of_output = 3\n",
    "params = 4 * ((size_of_input + 1) * size_of_output + size_of_output^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 12)                1044      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 1,083\n",
      "Trainable params: 1,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(GRU(12, input_shape=(20,16))); print  # original 100 ; \n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a68d0c7ccbe3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "%% this code to enable the right indentation when pressing Tab , Enter\n",
    "IPython.tab_as_tab_everywhere = function(use_tabs) {\n",
    "    if (use_tabs === undefined) {\n",
    "        use_tabs = true; \n",
    "    }\n",
    "\n",
    "    // apply setting to all current CodeMirror instances\n",
    "    IPython.notebook.get_cells().map(\n",
    "        function(c) {  return c.code_mirror.options.indentWithTabs=use_tabs;  }\n",
    "    );\n",
    "    // make sure new CodeMirror instances created in the future also use this setting\n",
    "    CodeMirror.defaults.indentWithTabs=use_tabs;\n",
    "\n",
    "    };\n",
    "\n",
    "IPython.tab_as_tab_everywhere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,15,16]:\n",
    "\tfor j in [20,50,40]:\n",
    "\t\tprint (i,\"\",j)\n",
    "\t\t\n",
    "\t\t\n",
    "\n",
    "X_train, Y_train, X_test ,Y_test =myDataset \n",
    "print (X_train.shape ,Y_train.shape,X_test.shape, Y_test.shape)\n",
    "#print (X_test)\n",
    "\n",
    "mu = np.average([np.average(X_train),np.average(X_test)]) \n",
    "import matplotlib as mplib\n",
    "mplib.plot(X_train[0,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix='C:/Users/alame/OneDrive - unige.it/Documents/TactileDataset/cleand (6144)/Average in time/output=256/Dataset/'\n",
    "#\n",
    "X1 = read_csv(prefix+'rolling/'+'rolling_all_256.txt', header=None, delim_whitespace=False) \n",
    "X2 = read_csv(prefix+'sliding/'+'sliding_all_256.txt', header=None, delim_whitespace=False) \n",
    "X3 = read_csv(prefix+'brushing/'+'brushing_all_256.txt', header=None, delim_whitespace=False) \n",
    "n_features = 16\n",
    "timelength = 256\n",
    "#A=X1.values\n",
    "#B=X2.values\n",
    "Xlen= X1.shape[0]\n",
    "X1=X1.values\n",
    "X2=X2.values\n",
    "X3=X3.values\n",
    "\n",
    "X1_train = X1[0:4*Xlen//5,:]\n",
    "X2_train = X2[0:4*Xlen//5,:]\n",
    "X3_train = X3[0:4*Xlen//5,:]\n",
    "\n",
    "X_train = np.zeros((X1_train.shape[0]*3,X1_train.shape[1]))\n",
    "X_train [ 0:X1_train.shape[0],:] = X1_train\n",
    "X_train [X1_train.shape[0]:X1_train.shape[0]*2,:]=X2_train\n",
    "X_train [X1_train.shape[0]*2:X1_train.shape[0]*3,:]=X3_train\n",
    "\n",
    "X1_test = X1[4*Xlen//5:Xlen,:]\n",
    "X2_test = X2[4*Xlen//5:Xlen,:]\n",
    "X3_test = X3[4*Xlen//5:Xlen,:]\n",
    "\n",
    "X_test = np.zeros((X1_test.shape[0]*3,X1_test.shape[1]))\n",
    "X_test[ 0:X1_test.shape[0],:] = X1_test\n",
    "X_test [X1_test.shape[0]:X1_test.shape[0]*2,:]=X2_test\n",
    "X_test [X1_test.shape[0]*2:X1_test.shape[0]*3,:]=X3_test\n",
    "\n",
    "#X= np.concatenate (A,B,1)\n",
    "#print (np.shape(X1))\n",
    "#print (np.shape(X2))\n",
    "Y = read_csv(prefix + 'y.txt', header=None, delim_whitespace=True)\n",
    "Y = Y.values\n",
    "Y = to_categorical(Y)\n",
    "Ylen = Y.shape[0]\n",
    "Y1 = Y[0:Ylen//3,:]\n",
    "Y2 = Y[Ylen//3:2*Ylen//3,:]\n",
    "Y3 = Y[2*Ylen//3:Ylen,:]\n",
    "\n",
    "\n",
    "Y1_train = Y1[0:4*Ylen//5//3,:]\n",
    "Y2_train = Y2[0:4*Ylen//5//3,:]\n",
    "Y3_train = Y3[0:4*Ylen//5//3,:]\n",
    "\n",
    "Y_train = np.zeros((Y1_train.shape[0]*3,Y1_train.shape[1]))\n",
    "\n",
    "Y_train [ 0:Y1_train.shape[0],:] = Y1_train\n",
    "Y_train [Y1_train.shape[0]:Y1_train.shape[0]*2,:] = Y2_train\n",
    "Y_train [Y1_train.shape[0]*2:Y1_train.shape[0]*3,:] = Y3_train\n",
    "\n",
    "#Y_train = Y1_train.append(Y2_train)\n",
    "Y1_test = Y1[4*Ylen//5//3:Ylen//3,:]\n",
    "Y2_test = Y2[4*Ylen//5//3:Ylen//3,:]\n",
    "Y3_test = Y3[4*Ylen//5//3:Ylen//3,:]\n",
    "\n",
    "Y_test = np.zeros((Y1_test.shape[0]*3,Y1_test.shape[1]))\n",
    "Y_test [ 0:Y1_test.shape[0],:] = Y1_test\n",
    "Y_test [Y1_test.shape[0]:Y1_test.shape[0]*2,:]=Y2_test\n",
    "Y_test [Y1_test.shape[0]*2:Y1_test.shape[0]*3,:]=Y3_test\n",
    "\n",
    "X_train= np.reshape((X_train),(X_train.shape[0]//timelength,256,n_features))\n",
    "X_test= np.reshape((X_test),(X_test.shape[0]//timelength,256,n_features))\n",
    "#Y_train= np.reshape((Y_train),(Y_train.shape[0]//timelength,-1,8192))\n",
    "#Y_test= np.reshape((Y_test),(Y_test.shape[0]//timelength,-1,8192))\n",
    "#return X_train, Y_train, X_test ,Y_test \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
