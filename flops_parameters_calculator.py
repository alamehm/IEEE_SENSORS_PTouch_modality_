# -*- coding: utf-8 -*-
"""FLOPS_Parameters_calculator

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_OU4y9G8z5DXbJqXwQWvov_GLNxvuCeq
"""

from google.colab import drive
drive.mount('/content/drive')
!ls "/content/drive/My Drive"

from keras.models import Model
from keras.layers import Input
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.pooling import MaxPooling2D
from keras.optimizers import Adam,SGD
from sklearn.model_selection import train_test_split
import numpy as np
import pickle
from sklearn.utils import shuffle
from keras import backend as K
from keras.utils import np_utils
import matplotlib.pyplot as plt
from keras.preprocessing.image import load_img
# import os,cv2
from keras.layers import Dropout
from keras.layers import BatchNormalization , Activation
from keras.models import Sequential
from keras.layers import concatenate
from keras import backend as K
K.common.image_dim_ordering()
import tensorflow as tf
from keras.preprocessing import image
from keras.applications.imagenet_utils import preprocess_input
import os,cv2
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array
import scipy.io as sio
from keras.layers import LSTM, GRU

# Multiple Inputs

####################### create dataset
data_path = r'/content/drive/My Drive/DeepLearning/Article extension/RGB/Images(average 256)'
data_dir_list = os.listdir(data_path)
data_dir_list.sort()
img_data_list=[]
img_name_list=[]
for dataset in data_dir_list:
    img_list=os.listdir(data_path+'/'+ dataset)
    print ('Loaded the images of dataset-'+'{}\n'.format(dataset))
    for img in img_list:
        if img == 'desktop.ini' :
            continue
        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )
        #input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)
        input_img_resize=cv2.resize(input_img,(64,64))
        img_data_list.append(input_img_resize)
        img_name_list.append(img)
        
######### load the data
num_channel=3
dataset = np.array(img_data_list)
dataset = dataset.astype('float32')
dataset /= 255
print (dataset.shape)
if num_channel==1:
	if K.common.image_dim_ordering()=='th':
		dataset= np.expand_dims(dataset, axis=1) 
		print (dataset.shape)
	else:
		dataset= np.expand_dims(dataset, axis=4) 
		print (dataset.shape)
		
else:
	if K.common.image_dim_ordering()=='th':
		img_data=np.rollaxis(dataset,3,1)
		print (dataset.shape)
print (dataset.shape)
num_channel=2
num_classes =3
num_of_samples = dataset.shape[0]
label=np.ones((num_of_samples,),dtype = int)
for i in range(0,3):
  label[i*260:(i+1)*260]=i
  print(label[i*260])


#print(img_name_list)
target_names = ['brushing','rolling','sliding']

Labels = np_utils.to_categorical(label, num_classes)

#Shuffle the dataset
#x,y,Filenames = shuffle(img_data,Y,img_name_list, random_state=2)

# X_train, x_test, Y_train, y_test, train_Files, test_files = train_test_split(x,y,Filenames, test_size=0.2, random_state=2)
# x_test, x_val, y_test, y_val, x_Files, val_files = train_test_split(x_test,y_test,test_files, test_size=0.5, random_state=2)

from keras.models import Model
from keras.layers import Input
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.pooling import MaxPooling2D
from keras.optimizers import Adam,SGD
from sklearn.model_selection import train_test_split
import numpy as np
import pickle
from sklearn.utils import shuffle
from keras import backend as K
from keras.utils import np_utils
import matplotlib.pyplot as plt
from keras.preprocessing.image import load_img
# import os,cv2
from keras.layers import Dropout
from keras.layers import BatchNormalization , Activation
from keras.models import Sequential
from keras.layers import concatenate
from keras import backend as K
K.common.image_dim_ordering()
import tensorflow as tf
from keras.preprocessing import image
from keras.applications.imagenet_utils import preprocess_input
import os,cv2
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array
import scipy.io as sio
from keras.layers import LSTM, GRU
#############################################################
from keras.applications.inception_resnet_v2 import InceptionResNetV2
model = InceptionResNetV2(include_top=False, input_shape=(400, 400, 3))
flat1 = Flatten()(model.outputs)
output = Dense(3, activation='softmax')(flat1 )
model = Model(inputs=model.inputs, outputs=output)
model.compile (loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model.summary()
#############################################################
# from keras.applications.resnet50 import ResNet50
# model = ResNet50(weights="imagenet", include_top=False,input_tensor=Input(shape=(64, 64, 3)))
# x = model.output
# x = Flatten(name='flatten')(x)
# model = Model(inputs=model.input, outputs=x)
# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# print(model.summary())
#################################################################
# from keras.applications.resnet_v2 import ResNet152V2
# model = ResNet152V2(weights="imagenet", include_top=False,input_tensor=Input(shape=(64, 64, 3)))
# x = model.output
# x = Flatten(name='flatten')(x)
# model = Model(inputs=model.input, outputs=x)
# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# print(model.summary())
#################################################################
# from keras.applications.vgg16 import VGG16
# model = VGG16(weights="imagenet", include_top=False,input_tensor=Input(shape=(64, 64, 3)))
# x = model.output
# x = Flatten(name='flatten')(x)
# model = Model(inputs=model.input, outputs=x)
# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# print(model.summary())
##################################################################
# from keras.applications.mobilenet_v2 import MobileNetV2
# model = MobileNetV2(weights="imagenet", include_top=False,input_tensor=Input(shape=(64, 64, 3)))
# x = Flatten(name='flatten')(model.output)
# model = Model(inputs=model.inputs, outputs=x)
# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# print(model.summary())
##################################################################
#n_features = 16
#n_timesteps = 20
#n_outputs = 3
#model = Sequential ()
#model.add (LSTM (100, input_shape = (n_timesteps, n_features), return_sequences = True)); print ("first lstm layer 100 neurons") # original 100
#model.add (LSTM (10, input_shape = (n_timesteps, n_features)))
#model.add (Dense (n_outputs, activation = 'softmax'))
#model.compile (loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
#model.summary()
##################################################################
#n_features = 64
#n_timesteps = 20
#n_outputs = 10
#model = Sequential ()
#model.add (GRU (10, input_shape = (n_timesteps, n_features))) 
#model.add (Dense (n_outputs, activation = 'softmax'))
#model.compile (loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
#model.summary ()
##################################################################
#from keras.layers import ConvLSTM2D
#model = Sequential()
#model.add(ConvLSTM2D(filters=32, kernel_size=(3, 3),input_shape=(24, 64, 64, 3),data_format='channels_last', padding='same', return_sequences=True))
#model.add(BatchNormalization())
#model.add(Dropout(0.5))
#model.add(Flatten())
#model.add(Dense(100, activation='relu'))
#model.add(Dense(3, activation='softmax'))
#model.summary()

save_path = r'/content/drive/My Drive/DeepLearning'
model.save(os.path.join(save_path,"InceptionResNetV2.h5"))

from keras.models import Model
from keras.layers import Input
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.pooling import MaxPooling2D
from keras.optimizers import Adam,SGD
from sklearn.model_selection import train_test_split
import numpy as np
import pickle
from sklearn.utils import shuffle
from keras import backend as K
from keras.utils import np_utils
import matplotlib.pyplot as plt
from keras.preprocessing.image import load_img
# import os,cv2
from keras.layers import Dropout
from keras.layers import BatchNormalization , Activation
from keras.models import Sequential
from keras.layers import concatenate
from keras import backend as K
K.common.image_dim_ordering()
import tensorflow as tf
from keras.preprocessing import image
from keras.applications.imagenet_utils import preprocess_input
import os,cv2
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array
import scipy.io as sio
from keras.layers import LSTM, GRU
def get_flops(model_h5_path ):
    session = tf.compat.v1.Session()
    graph = tf.compat.v1.get_default_graph()


    with graph.as_default():
        with session.as_default():
            model = tf.keras.models.load_model(model_h5_path)

            run_meta = tf.compat.v1.RunMetadata()
            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()

            # Optional: save printed results to file
            # flops_log_path = os.path.join(tempfile.gettempdir(), 'tf_flops_log.txt')
            # opts['output'] = 'file:outfile={}'.format(flops_log_path)

            # We use the Keras session graph in the call to the profiler.
            flops = tf.compat.v1.profiler.profile(graph=graph,run_meta=run_meta, cmd='op', options=opts)

            return flops.total_float_ops
get_flops('/content/drive/My Drive/DeepLearning/InceptionResNetV2.h5')